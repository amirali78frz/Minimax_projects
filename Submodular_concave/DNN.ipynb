{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c800b4d3",
   "metadata": {},
   "source": [
    "Below is the code for building a datatset and training a supervised U-net for online image segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d120735",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "\n",
    "H, W = 50, 50\n",
    "\n",
    "s = 50.0 / 80.0\n",
    "top_row = 22 * s; top_col = 40 * s\n",
    "top_r_y = 12 * s; top_r_x = 18 * s\n",
    "bot_row = 55 * s; bot_col = 40 * s\n",
    "bot_r_y = 12 * s; bot_r_x = 18 * s\n",
    "cen_row = 38 * s; cen_col = 40 * s\n",
    "cen_r_y = 10 * s; cen_r_x = 10 * s\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 2. Base image + seed selection (offline static)\n",
    "# -------------------------------------------------------\n",
    "def build_base_img_and_seeds(rng):\n",
    "    img = np.ones((H, W)) * 120\n",
    "    yy, xx = np.ogrid[:H, :W]\n",
    "\n",
    "    # base dumbbell\n",
    "    mask_top = (yy - top_row)**2 / top_r_y**2 + (xx - top_col)**2 / top_r_x**2 <= 1\n",
    "    img[mask_top] = 60\n",
    "    mask_bottom = (yy - bot_row)**2 / bot_r_y**2 + (xx - bot_col)**2 / bot_r_x**2 <= 1\n",
    "    img[mask_bottom] = 60\n",
    "    mask_center = (yy - cen_row)**2 / cen_r_y**2 + (xx - cen_col)**2 / cen_r_x**2 <= 1\n",
    "    img[mask_center] = 90\n",
    "\n",
    "    # seeds BEFORE noise (same logic as your offline code)\n",
    "    coords_60 = np.argwhere(img == 60)\n",
    "    coords_90 = np.argwhere(img == 90)\n",
    "    coords_120 = np.argwhere(img == 120)\n",
    "\n",
    "    n_fg = 50\n",
    "    n_bg = 50\n",
    "    n_bg_90_min = 10\n",
    "\n",
    "    bg90_indices = rng.choice(len(coords_90), size=n_bg_90_min, replace=False)\n",
    "    bg_seeds_90 = coords_90[bg90_indices]\n",
    "\n",
    "    coords_bg_rest = np.vstack([coords_90, coords_120])\n",
    "    remaining = n_bg - n_bg_90_min\n",
    "    bg_rest_indices = rng.choice(len(coords_bg_rest), size=remaining, replace=False)\n",
    "    bg_seeds_rest = coords_bg_rest[bg_rest_indices]\n",
    "\n",
    "    fg_indices = rng.choice(len(coords_60), size=n_fg, replace=False)\n",
    "    fg_seeds = [(int(r), int(c)) for r, c in coords_60[fg_indices]]\n",
    "    bg_seeds = [(int(r), int(c)) for r, c in np.vstack([bg_seeds_90, bg_seeds_rest])]\n",
    "\n",
    "    return img, np.array(fg_seeds, dtype=int), np.array(bg_seeds, dtype=int)\n",
    "\n",
    "# -------------------------------------------------------\n",
    "# 3. Transform image AND seeds together for frame t\n",
    "#    (seeds are always kept same cardinality via clipping)\n",
    "# -------------------------------------------------------\n",
    "def transform_image_and_seeds(t, T_total, fg_seeds_base, bg_seeds_base, rng):\n",
    "    \"\"\"\n",
    "    For frame index t in 0..T_total-1, return:\n",
    "      - img_noisy_t: transformed, noisy image\n",
    "      - fg_seeds_t, bg_seeds_t: transformed seeds (int pixel coords), same lengths as base.\n",
    "    \"\"\"\n",
    "    # motion parameters\n",
    "    tau = t / T_total\n",
    "    angle_deg = 720 * tau              # 2 full rotations over the clip\n",
    "    shift_row = 5 * np.sin(2 * np.pi * tau)\n",
    "    shift_col = 5 * np.cos(2 * np.pi * 1.5 * tau)\n",
    "\n",
    "    theta = np.deg2rad(angle_deg)\n",
    "    cos_t, sin_t = np.cos(theta), np.sin(theta)\n",
    "    cy0, cx0 = cen_row, cen_col  # rotation center\n",
    "\n",
    "    # transformed dumbbell (analytic)\n",
    "    img = np.ones((H, W)) * 120\n",
    "    yy, xx = np.indices((H, W))\n",
    "\n",
    "    ellipses = [\n",
    "        (top_row, top_col, top_r_y, top_r_x, 60),\n",
    "        (bot_row, bot_col, bot_r_y, bot_r_x, 60),\n",
    "        (cen_row, cen_col, cen_r_y, cen_r_x, 90),\n",
    "    ]\n",
    "\n",
    "    for cy, cx, ry, rx, val in ellipses:\n",
    "        dy = cy - cy0\n",
    "        dx = cx - cx0\n",
    "        cy_r = cy0 + cos_t * dy - sin_t * dx + shift_row\n",
    "        cx_r = cx0 + sin_t * dy + cos_t * dx + shift_col\n",
    "        mask = ((yy - cy_r) ** 2) / (ry ** 2) + ((xx - cx_r) ** 2) / (rx ** 2) <= 1\n",
    "        img[mask] = val\n",
    "\n",
    "    # transform seeds with same rotation+translation, then clip to image bounds\n",
    "    def transform_seed_array(seeds_base):\n",
    "        seeds_new = []\n",
    "        for (r0, c0) in seeds_base:\n",
    "            dy = r0 - cy0\n",
    "            dx = c0 - cx0\n",
    "            r = cy0 + cos_t * dy - sin_t * dx + shift_row\n",
    "            c = cx0 + sin_t * dy + cos_t * dx + shift_col\n",
    "            r_i = int(np.round(r))\n",
    "            c_i = int(np.round(c))\n",
    "            # clip to valid pixel range\n",
    "            r_i = min(max(r_i, 0), H - 1)\n",
    "            c_i = min(max(c_i, 0), W - 1)\n",
    "            seeds_new.append((r_i, c_i))\n",
    "        return np.array(seeds_new, dtype=int)\n",
    "\n",
    "    fg_seeds_t = transform_seed_array(fg_seeds_base)\n",
    "    bg_seeds_t = transform_seed_array(bg_seeds_base)\n",
    "\n",
    "    # add noise\n",
    "    noise = rng.normal(0, 10, (H, W))\n",
    "    img_noisy = np.clip(img + noise, 0, 255)\n",
    "\n",
    "    return img_noisy, fg_seeds_t, bg_seeds_t\n",
    "\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "img_base, fg_seeds_base, bg_seeds_base = build_base_img_and_seeds(rng)\n",
    "\n",
    "\n",
    "def transform_image_and_seeds_random(\n",
    "    t, T_total, fg_base, bg_base, rng\n",
    "):\n",
    "    tau = t / T_total\n",
    "\n",
    "    angle_deg = rng.uniform(360, 1080) * tau\n",
    "    shift_row = rng.uniform(2, 8) * np.sin(2*np.pi*tau + rng.uniform(0, 2*np.pi))\n",
    "    shift_col = rng.uniform(2, 8) * np.cos(2*np.pi*1.3*tau + rng.uniform(0, 2*np.pi))\n",
    "\n",
    "    theta = np.deg2rad(angle_deg)\n",
    "    cos_t, sin_t = np.cos(theta), np.sin(theta)\n",
    "\n",
    "    img = np.ones((H, W)) * 120\n",
    "    yy, xx = np.indices((H, W))\n",
    "\n",
    "    ellipses = [\n",
    "        (top_row, top_col, top_r_y, top_r_x, 60),\n",
    "        (bot_row, bot_col, bot_r_y, bot_r_x, 60),\n",
    "        (cen_row, cen_col, cen_r_y, cen_r_x, 90),\n",
    "    ]\n",
    "\n",
    "    for cy, cx, ry, rx, val in ellipses:\n",
    "        dy = cy - cen_row\n",
    "        dx = cx - cen_col\n",
    "        cy_r = cen_row + cos_t*dy - sin_t*dx + shift_row\n",
    "        cx_r = cen_col + sin_t*dy + cos_t*dx + shift_col\n",
    "        mask = ((yy-cy_r)**2)/(ry**2) + ((xx-cx_r)**2)/(rx**2) <= 1\n",
    "        img[mask] = val\n",
    "\n",
    "    def transform_seeds(seeds):\n",
    "        out = []\n",
    "        for r0, c0 in seeds:\n",
    "            dy, dx = r0-cen_row, c0-cen_col\n",
    "            r = cen_row + cos_t*dy - sin_t*dx + shift_row\n",
    "            c = cen_col + sin_t*dy + cos_t*dx + shift_col\n",
    "            out.append((int(np.clip(r,0,H-1)), int(np.clip(c,0,W-1))))\n",
    "        return np.array(out)\n",
    "\n",
    "    fg = transform_seeds(fg_base)\n",
    "    bg = transform_seeds(bg_base)\n",
    "\n",
    "    noise = rng.normal(0, rng.uniform(5,15), (H,W))\n",
    "    img = np.clip(img + noise, 0, 255)\n",
    "\n",
    "    return img, fg, bg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b0246ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DumbbellDataset(Dataset):\n",
    "    def __init__(self, n_samples, rng):\n",
    "        self.n_samples = n_samples\n",
    "        self.rng = rng\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # random \"time\" index\n",
    "        t = self.rng.integers(0, self.n_samples)\n",
    "\n",
    "        # ---------------------------------------------------\n",
    "        # 1. Build transformed dumbbell image (analytic)\n",
    "        # ---------------------------------------------------\n",
    "        tau = t / self.n_samples\n",
    "        angle_deg = 720 * tau\n",
    "        shift_row = 5 * np.sin(2 * np.pi * tau)\n",
    "        shift_col = 5 * np.cos(2 * np.pi * 1.5 * tau)\n",
    "\n",
    "        theta = np.deg2rad(angle_deg)\n",
    "        cos_t, sin_t = np.cos(theta), np.sin(theta)\n",
    "        cy0, cx0 = cen_row, cen_col\n",
    "\n",
    "        yy, xx = np.indices((H, W))\n",
    "        img = np.ones((H, W)) * 120\n",
    "\n",
    "        ellipses = [\n",
    "            (top_row, top_col, top_r_y, top_r_x, 60),\n",
    "            (bot_row, bot_col, bot_r_y, bot_r_x, 60),\n",
    "            (cen_row, cen_col, cen_r_y, cen_r_x, 90),\n",
    "        ]\n",
    "\n",
    "        for cy, cx, ry, rx, val in ellipses:\n",
    "            dy = cy - cy0\n",
    "            dx = cx - cx0\n",
    "            cy_r = cy0 + cos_t * dy - sin_t * dx + shift_row\n",
    "            cx_r = cx0 + sin_t * dy + cos_t * dx + shift_col\n",
    "            mask = ((yy - cy_r) ** 2) / (ry ** 2) + ((xx - cx_r) ** 2) / (rx ** 2) <= 1\n",
    "            img[mask] = val\n",
    "\n",
    "        # ---------------------------------------------------\n",
    "        # 2. Build exact GT mask (pixels with value 60)\n",
    "        # ---------------------------------------------------\n",
    "        mask_gt = (img == 60).astype(np.float32)\n",
    "\n",
    "        # ---------------------------------------------------\n",
    "        # 3. Add noise to image for NN input (optional)\n",
    "        # ---------------------------------------------------\n",
    "        img_noisy = np.clip(img + self.rng.normal(0, 10, (H, W)), 0, 255)\n",
    "        img_noisy = img_noisy.astype(np.float32) / 255.0\n",
    "\n",
    "        return (\n",
    "            torch.from_numpy(img_noisy).unsqueeze(0),  # (1,H,W)\n",
    "            torch.from_numpy(mask_gt).unsqueeze(0)    # (1,H,W)\n",
    "        )\n",
    "\n",
    "\n",
    "class DumbbellDatasetRand(Dataset):\n",
    "    def __init__(self, n_samples, rng):\n",
    "        self.n_samples = n_samples\n",
    "        self.rng = rng\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # random \"time\" index\n",
    "        t = self.rng.integers(0, self.n_samples)\n",
    "\n",
    "        # ---------------------------------------------------\n",
    "        # 1. Build transformed dumbbell image (analytic)\n",
    "        # ---------------------------------------------------\n",
    "        tau = t / self.n_samples\n",
    "        angle_deg = self.rng.uniform(360, 1080) * tau\n",
    "        shift_row = self.rng.uniform(2, 8) * np.sin(2*np.pi*tau + self.rng.uniform(0, 2*np.pi))\n",
    "        shift_col = self.rng.uniform(2, 8) * np.cos(2*np.pi*1.3*tau + self.rng.uniform(0, 2*np.pi))\n",
    "\n",
    "        theta = np.deg2rad(angle_deg)\n",
    "        cos_t, sin_t = np.cos(theta), np.sin(theta)\n",
    "        cy0, cx0 = cen_row, cen_col\n",
    "\n",
    "        yy, xx = np.indices((H, W))\n",
    "        img = np.ones((H, W)) * 120\n",
    "\n",
    "        ellipses = [\n",
    "            (top_row, top_col, top_r_y, top_r_x, 60),\n",
    "            (bot_row, bot_col, bot_r_y, bot_r_x, 60),\n",
    "            (cen_row, cen_col, cen_r_y, cen_r_x, 90),\n",
    "        ]\n",
    "\n",
    "        for cy, cx, ry, rx, val in ellipses:\n",
    "            dy = cy - cy0\n",
    "            dx = cx - cx0\n",
    "            cy_r = cy0 + cos_t * dy - sin_t * dx + shift_row\n",
    "            cx_r = cx0 + sin_t * dy + cos_t * dx + shift_col\n",
    "            mask = ((yy - cy_r) ** 2) / (ry ** 2) + ((xx - cx_r) ** 2) / (rx ** 2) <= 1\n",
    "            img[mask] = val\n",
    "\n",
    "        # ---------------------------------------------------\n",
    "        # 2. Build exact GT mask (pixels with value 60)\n",
    "        # ---------------------------------------------------\n",
    "        mask_gt = (img == 60).astype(np.float32)\n",
    "\n",
    "        # ---------------------------------------------------\n",
    "        # 3. Add noise to image for NN input (optional)\n",
    "        # ---------------------------------------------------\n",
    "        img_noisy = np.clip(img + self.rng.normal(0, 10, (H, W)), 0, 255)\n",
    "        img_noisy = img_noisy.astype(np.float32) / 255.0\n",
    "\n",
    "        return (\n",
    "            torch.from_numpy(img_noisy).unsqueeze(0),  # (1,H,W)\n",
    "            torch.from_numpy(mask_gt).unsqueeze(0)    # (1,H,W)\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b007aac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet params: 1058977\n",
      "Epoch 1: loss=0.1928\n",
      "Epoch 2: loss=0.0150\n",
      "Epoch 3: loss=0.0107\n",
      "Epoch 4: loss=0.0088\n",
      "Epoch 5: loss=0.0073\n",
      "Epoch 6: loss=0.0065\n",
      "Epoch 7: loss=0.0051\n",
      "Epoch 8: loss=0.0034\n",
      "Epoch 9: loss=0.0023\n",
      "Epoch 10: loss=0.0018\n",
      "Epoch 11: loss=0.0016\n",
      "Epoch 12: loss=0.0017\n",
      "Epoch 13: loss=0.0014\n",
      "Epoch 14: loss=0.0014\n",
      "Epoch 15: loss=0.0014\n",
      "Epoch 16: loss=0.0013\n",
      "Epoch 17: loss=0.0013\n",
      "Epoch 18: loss=0.0013\n",
      "Epoch 19: loss=0.0012\n",
      "Epoch 20: loss=0.0013\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "def center_crop(tensor, target):\n",
    "    _, _, h, w = target.shape\n",
    "    _, _, H, W = tensor.shape\n",
    "    dh = (H - h) // 2\n",
    "    dw = (W - w) // 2\n",
    "    return tensor[:, :, dh:dh+h, dw:dw+w]\n",
    "def crop_to_match(tensor, target):\n",
    "    _, _, h, w = target.shape\n",
    "    _, _, H, W = tensor.shape\n",
    "    dh = (H - h) // 2\n",
    "    dw = (W - w) // 2\n",
    "    return tensor[:, :, dh:dh+h, dw:dw+w]\n",
    "\n",
    "\n",
    "class UNetSmall(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.enc1 = DoubleConv(1, 32)\n",
    "        self.enc2 = DoubleConv(32, 64)\n",
    "        self.enc3 = DoubleConv(64, 128)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "\n",
    "        self.dec2 = DoubleConv(128 + 64, 64)\n",
    "        self.dec1 = DoubleConv(64 + 32, 32)\n",
    "\n",
    "        self.up = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=False)\n",
    "        self.outc = nn.Conv2d(32, 1, 1)\n",
    "\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x1 = self.enc1(x)              # 50×50\n",
    "        x2 = self.enc2(self.pool(x1))  # 25×25\n",
    "        x3 = self.enc3(self.pool(x2))  # 12×12 (after floor)\n",
    "\n",
    "        # Decoder\n",
    "        x = self.up(x3)                # 24×24\n",
    "        x2_crop = center_crop(x2, x)\n",
    "        x = self.dec2(torch.cat([x, x2_crop], dim=1))\n",
    "\n",
    "        x = self.up(x)                 # 48×48\n",
    "        x1_crop = center_crop(x1, x)\n",
    "        x = self.dec1(torch.cat([x, x1_crop], dim=1))\n",
    "\n",
    "        return torch.sigmoid(self.outc(x))\n",
    "\n",
    "class UNetMedium(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.enc1 = DoubleConv(1, 48)\n",
    "        self.enc2 = DoubleConv(48, 96)\n",
    "        self.enc3 = DoubleConv(96, 192)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "\n",
    "        self.dec2 = DoubleConv(192 + 96, 96)\n",
    "        self.dec1 = DoubleConv(96 + 48, 48)\n",
    "\n",
    "        self.up = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=False)\n",
    "        self.outc = nn.Conv2d(48, 1, 1)\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x1 = self.enc1(x)             \n",
    "        x2 = self.enc2(self.pool(x1))  \n",
    "        x3 = self.enc3(self.pool(x2))  \n",
    "\n",
    "        # Decoder\n",
    "        x = self.up(x3)                \n",
    "        x2_crop = center_crop(x2, x)\n",
    "        x = self.dec2(torch.cat([x, x2_crop], dim=1))\n",
    "\n",
    "        x = self.up(x)              \n",
    "        x1_crop = center_crop(x1, x)\n",
    "        x = self.dec1(torch.cat([x, x1_crop], dim=1))\n",
    "\n",
    "        return torch.sigmoid(self.outc(x))\n",
    "\n",
    "# dataset = DumbbellDataset(n_samples=3000, rng=np.random.default_rng())\n",
    "dataset = DumbbellDatasetRand(n_samples=3000, rng=np.random.default_rng())\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "model = UNetMedium().to(device)\n",
    "# model = UNetSmall().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "print(\"UNet params:\", sum(p.numel() for p in model.parameters()))\n",
    "\n",
    "epochs = 20\n",
    "for ep in range(epochs):\n",
    "    model.train()\n",
    "    total = 0.0\n",
    "\n",
    "    for x, y in loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(x)\n",
    "        y_crop = crop_to_match(y, pred)\n",
    "        loss = criterion(pred, y_crop)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total += loss.item()\n",
    "\n",
    "    print(f\"Epoch {ep+1}: loss={total/len(loader):.4f}\")\n",
    "\n",
    "torch.save(model.state_dict(), \"unet_medium.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ed943f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "fps = 60\n",
    "T_sec = 180\n",
    "n_frames = fps * T_sec\n",
    "\n",
    "nn_video = []\n",
    "nn_seg_video = []\n",
    "with torch.no_grad():\n",
    "    for t in range(n_frames):\n",
    "        img, _, _ = transform_image_and_seeds(\n",
    "            t, n_frames, fg_seeds_base, bg_seeds_base, rng\n",
    "        )\n",
    "\n",
    "        img_t = torch.from_numpy(img.astype(np.float32) / 255.0)\n",
    "        img_t = img_t.unsqueeze(0).unsqueeze(0).to(device)\n",
    "\n",
    "        pred = model(img_t)\n",
    "        pred_resized = F.interpolate(pred, size=(H, W), mode='bilinear', align_corners=False)\n",
    "        seg = (pred_resized[0,0].cpu().numpy() > 0.5).astype(np.float32)\n",
    "        nn_seg_video.append(seg)\n",
    "        nn_video.append((img, seg))   # store BOTH\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "466da8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (50, 50) to (64, 64) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    }
   ],
   "source": [
    "import imageio.v2 as imageio\n",
    "def img_seg_to_uint8(img, seg):\n",
    "    out = img * seg\n",
    "    out = np.clip(out, 0, 255)\n",
    "    return out.astype(np.uint8)\n",
    "\n",
    "\n",
    "\n",
    "with imageio.get_writer(\"unet_segmentation.mp4\", fps=fps) as writer:\n",
    "    for img, seg in nn_video:\n",
    "        frame = img_seg_to_uint8(img, seg)\n",
    "        writer.append_data(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0a9bc75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean IoU over video: NN = 0.9045\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_iou(mask_pred, mask_gt):\n",
    "    \"\"\"\n",
    "    Compute IoU between predicted mask and ground-truth mask.\n",
    "    mask_pred, mask_gt: np.array of 0/1, same shape\n",
    "    \"\"\"\n",
    "    mask_pred = mask_pred.astype(bool)\n",
    "    mask_gt = mask_gt.astype(bool)\n",
    "    \n",
    "    intersection = np.logical_and(mask_pred, mask_gt).sum()\n",
    "    union = np.logical_or(mask_pred, mask_gt).sum()\n",
    "    \n",
    "    if union == 0:\n",
    "        return 1.0  # both empty → perfect match\n",
    "    return intersection / union\n",
    "\n",
    "fps = 60\n",
    "T_sec = 180\n",
    "n_frames = fps * T_sec\n",
    "\n",
    "gt_video = []       # ground truth masks (0/1)\n",
    "gt_video_orig = []  # noisy images\n",
    "\n",
    "rng = np.random.default_rng()\n",
    "\n",
    "# center of rotation\n",
    "cy0, cx0 = cen_row, cen_col\n",
    "\n",
    "yy, xx = np.indices((H, W))\n",
    "\n",
    "for t in range(n_frames):\n",
    "    tau = t / n_frames\n",
    "    angle_deg = 720 * tau\n",
    "    shift_row = 5 * np.sin(2 * np.pi * tau)\n",
    "    shift_col = 5 * np.cos(2 * np.pi * 1.5 * tau)\n",
    "\n",
    "    theta = np.deg2rad(angle_deg)\n",
    "    cos_t, sin_t = np.cos(theta), np.sin(theta)\n",
    "\n",
    "    # full dumbbell image (no noise)\n",
    "    img = np.ones((H, W)) * 120\n",
    "\n",
    "    ellipses = [\n",
    "        (top_row, top_col, top_r_y, top_r_x, 60),\n",
    "        (bot_row, bot_col, bot_r_y, bot_r_x, 60),\n",
    "        (cen_row, cen_col, cen_r_y, cen_r_x, 90),\n",
    "    ]\n",
    "\n",
    "    for cy, cx, ry, rx, val in ellipses:\n",
    "        dy = cy - cy0\n",
    "        dx = cx - cx0\n",
    "        cy_r = cy0 + cos_t * dy - sin_t * dx + shift_row\n",
    "        cx_r = cx0 + sin_t * dy + cos_t * dx + shift_col\n",
    "        mask = ((yy - cy_r) ** 2) / (ry ** 2) + ((xx - cx_r) ** 2) / (rx ** 2) <= 1\n",
    "        img[mask] = val\n",
    "\n",
    "    # GT mask: pixels exactly with value 60\n",
    "    mask_gt = (img == 60).astype(np.float32)\n",
    "\n",
    "    # noisy image for visualization or NN input\n",
    "    img_noisy = np.clip(img + rng.normal(0, 10, (H, W)), 0, 255)\n",
    "\n",
    "    gt_video.append(mask_gt)\n",
    "    gt_video_orig.append(img_noisy)\n",
    "    \n",
    "# Now compute IoU per frame for NN\n",
    "iou_nn = [compute_iou(pred, gt) for pred, gt in zip(nn_seg_video, gt_video)]\n",
    "mean_iou_nn = np.mean(iou_nn)\n",
    "\n",
    "# # Compute IoU per frame for your algorithm\n",
    "# iou_algo = [compute_iou(pred, gt) for pred, gt in zip(algo_seg_video, gt_video)]\n",
    "# mean_iou_algo = np.mean(iou_algo)\n",
    "\n",
    "print(f\"Mean IoU over video: NN = {mean_iou_nn:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7e93d7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (50, 50) to (64, 64) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    }
   ],
   "source": [
    "def img_mask_to_uint8(img, mask):\n",
    "    out = img * mask\n",
    "    out = np.clip(out, 0, 255)\n",
    "    return out.astype(np.uint8)\n",
    "\n",
    "with imageio.get_writer(\"unet_gt.mp4\", fps=fps) as writer:\n",
    "    for img, mask in zip(gt_video_orig, gt_video):  \n",
    "        frame = img_mask_to_uint8(img, mask)\n",
    "        writer.append_data(frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cbb87d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Precision: 0.9097\n",
      "Video Recall:    0.9937\n",
      "Video F1 score:  0.9498\n"
     ]
    }
   ],
   "source": [
    "def compute_prf(mask_pred, mask_gt, eps=1e-8):\n",
    "    \"\"\"\n",
    "    Compute precision, recall, F1 for a single binary mask.\n",
    "    mask_pred, mask_gt: np.ndarray of shape (H,W), values 0/1\n",
    "    \"\"\"\n",
    "    mask_pred = mask_pred.astype(bool)\n",
    "    mask_gt = mask_gt.astype(bool)\n",
    "\n",
    "    tp = np.logical_and(mask_pred, mask_gt).sum()\n",
    "    fp = np.logical_and(mask_pred, np.logical_not(mask_gt)).sum()\n",
    "    fn = np.logical_and(np.logical_not(mask_pred), mask_gt).sum()\n",
    "\n",
    "    precision = tp / (tp + fp + eps)\n",
    "    recall = tp / (tp + fn + eps)\n",
    "    f1 = 2 * precision * recall / (precision + recall + eps)\n",
    "    return precision, recall, f1\n",
    "\n",
    "# Lists to store per-frame metrics\n",
    "precisions, recalls, f1s = [], [], []\n",
    "\n",
    "# Loop over frames\n",
    "for pred, gt in zip(nn_seg_video, gt_video):\n",
    "    p, r, f = compute_prf(pred, gt)\n",
    "    precisions.append(p)\n",
    "    recalls.append(r)\n",
    "    f1s.append(f)\n",
    "\n",
    "# Average over the video\n",
    "mean_precision = np.mean(precisions)\n",
    "mean_recall = np.mean(recalls)\n",
    "mean_f1 = np.mean(f1s)\n",
    "\n",
    "print(f\"Video Precision: {mean_precision:.4f}\")\n",
    "print(f\"Video Recall:    {mean_recall:.4f}\")\n",
    "print(f\"Video F1 score:  {mean_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "06f8403f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABCIAAAFtCAYAAADS58tNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAz2ElEQVR4nO3de7hddXkg/vebK7nfCAkJIQnXcFUQHNSCOK1iOx3szZHWWnH6dNRqf8VOFajWp6MtTKv+LD+lVRlrtdqhU+xtbG0dHfHeSlQQCLcQEhJyv9/v+/fHPtHj4fuu5ISTdU6Sz+d59gN53/2utfbO2d+z8p511ls6nU4AAAAAtGHYYB8AAAAAcPLQiAAAAABaoxEBAAAAtEYjAgAAAGiNRgQAAADQGo0IAAAAoDUaEQAAAEBrNCIAAACA1mhEQAtK1wOllNf3iZ9XSvm9UsqoY7TfEaWUW0opT5RS9pRSVpRSPlh53oWllC+VUnaWUlaWUt5TShnej/3cWUr5+MAePcBzMxhrbynlnFLKR3v2e6CUcm/yvFeXUv6hlPJMKWV7KeU7pZRfTJ5rjQaOe0N5Te557g2llO/2rMnPlFI+VUqZVXmeNXkAaEQkSimvLaV8rZTy5VLKV0sp95dS/qKU8rLBPrZjoZTy/FLK7w3Qtj5USllaSlna8JzZpZR7Symbex739jy+W0pZVEp5y0AcS7LvV/Uc3+hjtY+K/xQRUyLiL/vEfzIifr3T6ew9Rvv9RET8PxHx/oh4RUTcEhG7ej+hlDIlIr4YEZ2IeFVEvCci/mtE/Ld+7Od9EfHaUso5A3DMnMSsvc9pW9beZxuMtfeiiPipiHi855H5rYjYHhFvi4jrI+LLEfGXpZTf6P0kazSDyZr8nLZlTX62Ibsml1Kuj4j/GRHfjO5ae3NEXBMRnyulDOv1PGvyQOl0Oh59HhHxmohYHRFn9oqdFhHfj4g/HuzjO0av+cbul8OAbe/3ImLpETzv3oi4t0/s56L74f7lY/Rar46I/xMRw1t8f78REX9QiX88Iv7vMdrnKyNiX0RceJjn3RoRmyJiYq/YOyJiZ+/YEezvixHxgbbeU48T72HtHZDtWXt/dJ+DsfYO6/X/9/R9n3vlTq3E/jIinuoTs0Z7DMrDmjwg27Mm/+g+h/KafHdEfKdP7Pqev4MLesWsyQP0cEVE3X+KiK91Op2nDwU6nc7aiLg9IjYO2lGdJDqdzt9ExObodhmPxfa/1ul0Xt7pdA4ci+331dPtfHF0F7/e8XUR8Z8j4mWllE7P498P4K7/c3QX9UWHed5PRsS/dDqdrb1id0fEmIh4aZ9jfmUp5es9XfutpZSFpZSX96Q/G93urnWFo2XtHUTW3oHR6XQOHuHz1lfC34vuP/R6O6I1+jDrc4Q1mv6zJg8ia/LAONI1OSJGRsSWPrHNPf8tvWLW5AFy0r7ww9gbEf+ulDK1d7DT6fzPTqfznkN/Ll3v6LlM7aullG+WUn6zz+U7o0v394CeLqV8pZTyyVLKHaWU3T2XXv1mKeVfez50N5ZS/rJ0f090YSnl4lLKi0sp/6uU8mgp5bOllAlHuv9SyvWVbf9bKeWhUsrVvbbz1uhesh+9Lgm78Shf472llD+N7ofxuRgRET+ycBzB6z3cez2/z3tybWXbD/bkHyyl/HYppfTnvUz8eETsiIgHeu8vIv5jROyOiD+IiBf1PL5Zec0jDvdI9vvvIuLxUsqHS3cB3FlK+Zvy7N91WxARj/YO9Jx07OzJHTqWayPi76LbPf+5iPil6HZz9/c85ZsRMSMiLjnM+wEZa6+190RYe5+LF0dE3+bxYdfocvj1OcIaTf9Zk63JJ9Oa/GcRcXUp5VdKKRNLKedFxO9HxJf7/FDPmjxQBvuSjKH4iIhro7v4boyI/y8ifiIiRlWed1tELImI6T1/PjUinoqIm3s95wMR8XREzOz58wXR7bYt7fWcedG97Odzh/YTEX8dEd+NiN/q+fPYiFgeEb/Tz/0f2vbnI2J0T+zOiFjc57XcGJVL0Z7Da1wbR38p2tsiYk9EXNufYzmS97rPe3Jtn22viog5PX8+s+fP7+nve1l5jR+LiPsq8UPbu6qh9sae5zQ+kto9EbEtIr4e3d+Ne01ELIuIf4uI0ut5+yLipkr9ioi4rdef74qIzzYc64joLrC/NtifYY/j8xHW3oF4jdbeH9YNytrbZzvpZcCV5/54dP/BcWOf+GHX6DjM+tzzHGu0R78eYU0eiNdoTf5h3ZBfkyPitdFtihza5jciYnKf51iTB+gx6AcwVB8R8YLoLn6Hvhg39nywx/Xkx0f3pn/v6FP3hxGxtuf/x/bUv7fPc/4y6gvvr/SKvaUn1vv38u6JiL890v332fbre8V+pic2qVfsxr4f4IF8jQ3v873Rvezp3p4P+9aI+GpEnN+fY+nPcUSfhbfXtm/r87zbo9vdHNenrvG9rLzGf4iIz1fi10f3pHN8Q+20iLjicI+kdm90b4Q2rVfsmp7j/fFesX0R8ZuV+mei1+/xRfckZHtE3BQ939wqNesj4neP9efT48R9hLV3QF9jw/t8b1h7j8na22c7R9SI6HmNaw59nfXJHXaNjiNYn3ueZ4326NcjrMkD+hob3ud7w5o8qGtyRLwsuj/A+8PoNuFeExGPRPdGwsN7Pc+aPECPY3FZ4Qmh0+l8JyJeXUoZHxHXRXdh+q3oXj7zioi4MCJOiYjXl1J+qlfpxIjY0XPJ2PyIGB0Ri/ts/qnoXn7Z1zO9/n9HJbY9Iub2/P9h99/pdLb1iq/o9f+Hfv9pcjz7d6F6Oxavseb+TqdzbUREKeWa6F669DPRXQiO6Fgi4tzncByHtt33TrqPRfeSugsj4r5e8f6+l6dEdwHv69KIWNLpdLY3HNvGhu0ezqae7W/oFft6dBsUF0bEl3o9b3KlflL88HfjIiJ+N7q/zvXuiPhAKeWL0f0JxcO9nrMnuq8Xjoq198j2Edbeobz29kvpXvb++ej+BPOXK085kjX6SNbnCGs0/WRNPrJ9hDX5RFiTPxAR/9DpdG4+FCil3B/dX8N4VUT8TU/YmjxANCIqSimnRsT2Tqezu+dD8dmI+Gwp5c6I+PVSyuReT/9Ap9P5s2Q7pRZv8KybxXSefQOZvttM99+w7U6yrcxAvsZGnU7nq6WUj0XEu0op/6PPP6LTYymlPG8gdt93s8nz+vteboyImZX4pdHr9+QSr4/uCM7Dqe3/keh+M6o9t/fvGz4ave4FERFRSpkTEeOi1+/AdTqdLRHx1lLKb0b3EuKPRPcux1f1Kp0cbmDFUbL2Pou190cdL2vvESuljI2ey9Aj4j90Op0dlacddo0+wvU5whpNP1iTn8Wa/KNOtDV5QXTHd/5Ap9N5rJSyKyLO7hW2Jg8QN6use39E/Gwl/lh0P2gHo3szqd3R7Q7+QCllXunenCYi4onodrr6zoidPwDHeCT7748f/MO0lDKsp7s7WK/xv0f3pOymXrHDHctzOY5D217QJ35edC9RO9zUicN5LDmOZ93spuJ/R8SVR/Co+VxEXNpzInHINdG9K3DvBf/zEXFd6XXjp+hejrYrIr7Sd6OdTudAp9P5QkT8S0QMPxQvpUyP7iWB6YxmOAxrr7U34vhfe49Iz43V/jq6P8H8yU53GkHNEa/R2frcsz9rNP1lTbYmR5wka3J076N2ee9AKeWC6F4NsrRX2Jo8QDQicm/r/Q+4ni+WGyPic51OZ2tPZ/j9EXFjKeX8nueMjO7vUT0TEdHpdHZGxIeje/nUjJ7nLIhuZ+w5OZL999Pqnm1MjYgXRsSXnuNr/Kln7eHIX9uK6HY9f6OUMqkn1ngsz+W97rPtM3tq50T37/sDyU+o+uMbEXFmz9dQb1sj4ppSyjWllKtq3fROp7Oh0+ksPNwj2e/HImJDRPzvUsp/LKX8UkT8RUR8sdPpfL3X8z4S3W9af1NK+YlSyn+J7tzr/7fTM5qolPLR0r0D8y+UUl5WSnl3RPxqdG9OdMgV0T0x+ZE7HUM/WXutvTfGcbz2llLG9qyVvxARsyNi+qE/91wBccifRPfv670RMbXnWA49el/N1rhGH+H6HGGN5uhYk63JN8bJsSZ/JCJeU0r5QM9a+9roTr5YGhH/1Od51uSBULtxxMn+iIiro3v5zHeje9OYr/b8/3+LXjdSie7lP/81uh3Cb0X3A3Zr/OhEgtHR/cJbHt2bnfxpRLwvIp7oyf/7iPjX6H4h3h/dzvObo9sZ7PTsf35EfDS6i+PmiPjCkew/2fb1Pf/f6cm9tOe5IyLi73tyCyPip47yNX4lIv48Iv44ul3VeyNifuU9nh0/vDHP5p7//7Fe+XnRvZfBgxFx+xG+3sb3uuc51/d5T/5Lr23/ds/+/i0iHoqItx/Ne1l5raOi2xB4XZ/4j0XEw9G96c3qY/S1fE50F88d0f2dtj+PiCmV510YEf83ut3cVdE9Me59Y57fiohv9/xdbe15/1/VZxt3RHfE0aB/hj2Oz0dYe629J8DaGz+8kVvtMa/X85YeyfN6npuu0XEE63PP86zRHv16hDXZmnxyrcklul9z34/uefMzEfFXEXFWZZvW5AF4HPqi4hgp3d+f29XpdPb0it0V3bv/XjdoB3YCGsrvdSnljog4p9Pp/IfBPI5jpZQyPLqXtN3S6XQ+PdjHA0N5PTjRDOX3+kRfe4+UNZrBNpTXiRPNUH6vrcld1uQuv5px7N0UEb9z6A+llHkR8XMR8T8G6XhOZDfF0H2v3xcR15ZSzhvsAzlGXh3drvDdg30g0OOmGLrrwYnmphi67/WJvvYeKWs0g+2mGLrrxInmphi677U1ucuaHOGKiGOtlHJtdEe3jI7u3WVHR8RHOp3OJwbxsE5IQ/29LqXcEBGrOp3Os24AebwrpfxidH838auDfSwQMfTXgxPJUH+vT+S190hZoxlsQ32dOJEM9ffammxNPkQjAgAAAGiNX80AAAAAWqMRAQAAALRmRFOylOL3NgCOQKfTedbc64FmTQY4Msd6TbYeAxyZbD12RQQAAADQGo0IAAAAoDUaEQAAAEBrNCIAAACA1mhEAAAAAK3RiAAAAABaoxEBAAAAtEYjAgAAAGiNRgQAAADQGo0IAAAAoDUaEQAAAEBrNCIAAACA1mhEAAAAAK3RiAAAAABaoxEBAAAAtEYjAgAAAGiNRgQAAADQGo0IAAAAoDUaEQAAAEBrNCIAAACA1mhEAAAAAK3RiAAAAABaoxEBAAAAtEYjAgAAAGiNRgQAAADQGo0IAAAAoDUaEQAAAEBrNCIAAACA1mhEAAAAAK3RiAAAAABaoxEBAAAAtEYjAgAAAGiNRgQAAADQGo0IAAAAoDUaEQAAAEBrNCIAAACA1mhEAAAAAK3RiAAAAABaM2KwDwAA4GT18MMPV+P79u1LazZu3Jjmpk+fXo1Pnjw5rRkxIj8dPPXUU6vxkSNHpjUwVCxbtizNNX3Gtm3bVo3v2rUrrRk2rP7z3blz56Y1O3fuTHPZZ3np0qVpzaWXXprmYKhxRQQAAADQGo0IAAAAoDUaEQAAAEBrNCIAAACA1mhEAAAAAK0pnU4nT5aSJwH4gU6nU471PqzJMPjuu+++avzAgQNpzWc/+9k0t2nTpmr8vPPOS2u+9a1vpbnZs2dX4+PGjUtr9u/fn+Ze+9rXVuPDhw9Pa3bv3l2Njxo1Kq257LLL0tzRONZrsvX42Hj88cfT3OrVq9Pcjh07qvFvfOMbac2WLVvSXPaZaJq0kU3UmDdvXlozfvz4NJe9F5MmTUprXv/616e5rVu3VuNTp05Nay655JI0B0cqW49dEQEAAAC0RiMCAAAAaI1GBAAAANAajQgAAACgNRoRAAAAQGs0IgAAAIDWGN8JMACM74Tjy86dO9PcDTfckOY2b95cjZ911llpTdPYyg0bNlTjTSP1tm3bluYmTJhQjTed702fPj3Nbdy4sRo/55xz0prsNb385S9Pa5rGGGbH1/SeG985tC1evLgav/POO49qe+vXr6/GZ8yYkdasWLEizc2cObMaX7hwYVrzile8ohpftmxZWnPw4MF+H8NDDz2U1jR9LrMRp8uXL09r3vOe96S5K6+8Ms1Bb8Z3AgAAAINOIwIAAABojUYEAAAA0BqNCAAAAKA1GhEAAABAazQiAAAAgNYY3wkwAIzvhKHpHe94RzV+2WWXpTWf+tSn0lw2SnLlypVpzYIFC9LcaaedVo03jfXbvn17msvGfq5ZsyatmThxYpp78MEHq/Frrrkmrdm6dWs1vmrVqrRmy5Ytae63f/u3q/Fp06alNfPmzTO+c5A1fc29/e1vr8Z3796d1syePTvNjR49uhrfv39/WtO0r+wzVkr+ZTV8+PBqvGmk5gMPPJDmss9l09ja7LPXlGsaBzxlypQ0d91111Xjr3zlK9MaTk7GdwIAAACDTiMCAAAAaI1GBAAAANAajQgAAACgNRoRAAAAQGtMzQAYAKZmwOC59dZb09yECROq8QMHDqQ1GzZsSHMjR46sxpsmWTSZMWNGNd50fMuWLUtz2RSOffv2pTWTJ09Oc3v27On39pYsWVKNX3XVVWnNM888k+ayu/q/9a1vTWsuv/xyUzNa0PRZedvb3pbmxo0bV41nU18iIjZu3JjmVq9eXY03TcdZtGhRmjv11FOr8aZJGxdffHE13vS1vWvXrjSX2bRpU5prmpoxfvz4arxpPbn00kvT3JgxY6rxX/iFX0hrXvKSl6Q5TlymZgAAAACDTiMCAAAAaI1GBAAAANAajQgAAACgNRoRAAAAQGs0IgAAAIDWjBjsAwAAOBKvetWrqvGxY8emNcuXL6/GR40aldbcf//9ae7KK6+sxvfv35/WTJw4Mc0NHz68Gp85c2Zas3Tp0jSXjdtcv359WpON4WuSjUuMiJgzZ041/sQTT6Q1TeNKs7/fv/7rv05rLr/88jRH//3zP/9zNf7ud787rZk9e3aa27FjRzW+du3atCYbqRkRsXfv3mq8adTlpEmT0tw555xTjTeNunzwwQer8abPf9Pn8nnPe141nq0ZEfn7EBHxohe9qBqfN29eWtMkG916zz33HNX2OPm4IgIAAABojUYEAAAA0BqNCAAAAKA1GhEAAABAazQiAAAAgNZoRAAAAACtMb4TADguzJo1qxrfuHFjWrNv375qfNy4cWnNlClT0lw2Au+hhx5Ka3bv3p3m1q1bV41v27YtrfmJn/iJNHffffdV42effXZa0zTiMHufmkZ+ZmMWn3rqqbSmadRjNuIw+3pg4J1//vnVeNOo21WrVvV7P9OmTUtz2dd2RMTLXvayanz79u1pzdatW9NcNqZz6tSpac1ll11WjX/3u99Na7L1KSJ//+bOnZvWNK01nU6nGm8amdr0uRw9enQ13jQaec2aNdX4jBkz0hpOXK6IAAAAAFqjEQEAAAC0RiMCAAAAaI1GBAAAANAajQgAAACgNSW7g2pERCklTwLwA51OpxzrfViToe6GG25Ic5MmTarGDx48mNY03fW9lPpHffLkyWnN5s2b01w2leJ73/teWnPVVVeludWrV6e5zJ49e9Jcdp7YNHVk+vTp1XjTpI1du3aluaVLl1bjO3bsSGvuueeeY7omn4jr8fLly9PcH/3RH/V7e0888USae97znleNN32NNE3AyL6GTznllLSm6XP+ne98pxp/yUtektZkX4/ZtiKap4Rkk26aJmMsWbIkzWXTbIYNy38uPWJEPmBx5syZ1XjTxJ+dO3dW4x/+8IfTGo5/2TmyKyIAAACA1mhEAAAAAK3RiAAAAABaoxEBAAAAtEYjAgAAAGiNRgQAAADQmnwmCwDAceDuu+8e7EOIt73tbWnuzDPPTHPZuL0LL7wwrVm2bFm/99U01rNpRF82MnHWrFlpzeOPP16Nz507N62ZOnVqmsvGFWZjQjk6a9euTXPZ3+kZZ5yR1mSjc5u21zRSc+zYsWlu//791fiUKVPSmi1btqS57Gv14YcfTmsuuOCCavyiiy5Ka04//fQ099RTT1Xja9asSWuaxuBmn9kNGzakNU25bITv6NGj05oJEyakOU4+rogAAAAAWqMRAQAAALRGIwIAAABojUYEAAAA0BqNCAAAAKA1GhEAAABAa0qn08mTpeRJAH6g0+mUY70PazIcn5pGe2Y2btyY5mbOnJnmtm7d2u99NY3vzLbXNG4zGyF4NPuJiNi3b181Pnz48LTmL/7iL47pmnyyrce/+Iu/WI3PmzdvQPfTNEK0aWxldhyPPvpoWtM0SvK0006rxg8cOJDWDBtW//nutGnT0pqmcZvbtm3r17FFROzcuTPNrVy5sho/5ZRT0prx48f3e19No32zY/jkJz+Z1nD8y86RXREBAAAAtEYjAgAAAGiNRgQAAADQGo0IAAAAoDUaEQAAAEBr8tsXDxHf/OY309zf/d3fVeNNd1Fev359msvuDNu0vaa7565ataoab7prdNMdfJcsWVKN/8u//EtaAwAMrqYJGHv37q3GL7zwwrTmvvvuS3MLFiyoxseNG5fWZHeyj4iYPHlyNb5jx460Jpse0HQMkyZNSnMPPfRQNT527Ni0hoH1gQ98oBr/nd/5nbRm5MiRaS6bJNF0Xv3Sl740zWWfsenTp/f7GCLy8/FNmzalNdl0l6bJHU0TJubOnVuNZ/++iMjXk4iI2bNnV+NNn+XsNUXkk3Oatmc6Br25IgIAAABojUYEAAAA0BqNCAAAAKA1GhEAAABAazQiAAAAgNZoRAAAAACtKZ1OJ0+WkiePwne+8500d9ttt1Xjl1xySVozceLEavxb3/pWWtM06mnUqFHV+LZt29Ka0aNHp7ns+JrGdzZZt25dNb5169a0ZsqUKWnOCB0YOJ1OpxzrfQz0mszx701velM13vR95vTTT09z73znO5/zMdE/73rXu6rxtWvXpjUHDx5Mc9ko8t27d6c1peTLV1Z31llnpTXZueWGDRvSmqaxg9k4wHPPPTetede73nVM12TrcddrXvOaNNf0dTpz5sxqvOk8PfvajsjPkZu2d8opp6S5J598shrPjjsiYsmSJdV4NjYzonnEabaOL168OK1p+lw+/fTT1Xg2JjSi+T1fsWJFNd40vvMzn/lMmuPElZ0juyICAAAAaI1GBAAAANAajQgAAACgNRoRAAAAQGs0IgAAAIDWaEQAAAAArRnw8Z1f/vKX09zHPvax/m4uhg8fnuamT59ejWcjfCIixowZk+ayMTlN46GWL1+e5nbt2lWNN43UvP/++9PctddeW403jSudNm1amtu3b1813jSS9K677kpzcDIzvvPk86Uvfaka/9SnPpXWNI1q27NnTzXetI7PmTOnGn/wwQfTmqaRddn3p9tvvz2t4bn5jd/4jWq8aQTrypUr09zUqVOr8aZzo7PPPjvNZeM7n3rqqbRm3Lhx1Xh23hHR/Hqf//znV+PXX399WnPBBRcY3znIfu3Xfi3NZaPnJ0yYkNY05YYNq/9stWk07fbt29PcRz7ykTTXlre//e3VeNNxN71HTzzxRDXe9Nk788wz09yBAweq8T/+4z9Oazg5Gd8JAAAADDqNCAAAAKA1GhEAAABAazQiAAAAgNZoRAAAAACtOeqpGUuWLKnG77jjjnR7q1evTnPZXZ7Xrl2b1mR3eW6aZJHdYTwi4sknn6zGR40aldZMmjQpzW3ZsqUab5oE0jRRI7sj8NG8rxERO3bsqMabpoQsXbq0Gv/4xz+e1sDJwNSM49f69evT3Fve8pY0l03AuOiii9Kapu9p2d3Os2kaEfk63lRz6qmnprlsQsIHP/jBtIbn5g1veEM1Pnny5LTm4MGDaW7v3r3V+KZNm9KaCy+8MM1l0zaa7rQ/fvz4arzps9Y0sev1r399NX7ZZZelNcd6TbYePzc333xzNZ6dZ0ZEzJo1K81Zo7re9KY3pbnZs2dX44sWLUprmqYsfeITnzjyA+OkZmoGAAAAMOg0IgAAAIDWaEQAAAAArdGIAAAAAFqjEQEAAAC0RiMCAAAAaE3j+M7HH388Tf75n/95Nf7II4+k25s4cWKay8ZWNtVs3bq1Gt+/f39ak43UjMjHAj3xxBNpTdPxLVu2rBq/9tpr05qmUaHbtm2rxvft25fWjBkzJs19/vOfr8bnz5+f1mSjt17wghekNe9///vTHJwojO8c+rKxcHfffXdas3jx4jSXjdts+r7wwAMPpLls/W8aa5iNkG76Xtc0vjP7/vmhD30oreG5ueWWW6rxzZs3pzUHDhxIc+PGjavGm0Z+No0iz0a6Np17fO9736vG586dm9b86q/+app76UtfmuYyxnfCj/rpn/7pavxzn/tcy0fCycb4TgAAAGDQaUQAAAAArdGIAAAAAFqjEQEAAAC0RiMCAAAAaE3j1Iybb745TY4cObIa37hxY7q9JUuWpLlsUsPMmTPTmtWrV1fjkydPTmuarFq1qhofNizv12R3k47I74DetL1sckdE/v41HcPUqVPT3I4dO6rxUvIbTZ922mnV+IYNG9KaT3/602kOThSmZgwNTd+D3vzmN1fjl112WVqTfZ+JyKcQNE07mDZtWpqbMWNGNd40neDJJ5+sxs8444y0pmlyRzZR4xOf+ERaw7Hx1re+Nc1lE6wiIubMmVONN03N2LlzZ5rL6n7pl34prTmaKRcDzdQMgKHB1AwAAABg0GlEAAAAAK3RiAAAAABaoxEBAAAAtEYjAgAAAGiNRgQAAADQmsbxnTfddFOazEZ8PfPMM+n2tmzZ0o9D62oaN3X55ZdX49k4s4jmsWXZ9vbu3ZvWZCMwIyKuvPLKanzp0qVpTdMIreHDh1fjTa933rx5aW78+PHV+B133JHWAHXGd7Zn3bp1ae5XfuVX0tzZZ59djTeNVM5GVUfkY4vPPffctGbFihVpLhv5PHbs2LQmG9/c9L14zJgxaS47J2gapd30ffDOO+9Mc3AsGd8JMDQY3wkAAAAMOo0IAAAAoDUaEQAAAEBrNCIAAACA1mhEAAAAAK3RiAAAAABaM6Ip2TTS7LHHHqvG9+zZk9YsWLAgze3fv78az0aTRUQ89dRT1fi4cePSmmxEZ0TE+vXrq/FZs2alNU2vd/HixdX4xo0b05qmcaXz58+vxptGxX3kIx9JcwDHo9WrV6e5H/uxH0tzCxcurMbPO++8tGbt2rVpLhvt2TRetGl72YjrptGZ06dPr8anTZuW1mzbti3NzZgxoxp/8MEH05qXv/zlaQ4AoMYVEQAAAEBrNCIAAACA1mhEAAAAAK3RiAAAAABaoxEBAAAAtKZxakbTnb9XrVpVjTfdfbzpTufZXcGbpkhkdyx/8skn05rNmzenuYsuuqga37RpU1ozYcKEfu/rtNNOS2uaXu/KlSur8U9/+tNpDcCJZuzYsWlu69ataS77/tQ0nSmbIhERMWJE/VvoQw89lNZMmjQpze3cubMaP/3009OaFStWVONN056aXu+OHTuq8YsvvjitWbRoUZoDAKhxRQQAAADQGo0IAAAAoDUaEQAAAEBrNCIAAACA1mhEAAAAAK3RiAAAAABa0zi+841vfGOa+8IXvlCNL168OK1pGnW5ffv2ajwbTRYRsW/fvmp82rRpac3ZZ5+d5vbv31+Nz507N61p2lc20qxpvNyoUaPSnDGdAM1r6He/+900l41oztb+iIhHH300zc2ePbsanzhxYlqza9euNJeNsd6zZ09aM378+Gr8wIEDaU3T+M6sruk1ZWNMIyKuu+66avzyyy9Pa26//fY0BwCcGFwRAQAAALRGIwIAAABojUYEAAAA0BqNCAAAAKA1GhEAAABAazQiAAAAgNY0ju88ePBgmlu/fn01/uIXvzit+f73v5/mspFmZ555ZlqTHd+aNWvSmnXr1qW5qVOn9ms/EREPPPBAmstGhU6ePDmt2bZtW5rj8H7+53++Gs/G4kVEjBs3Ls1lo/GOZkxt08i8j3/842kO+FGllDSXjehsqmtaH174whemufvuu68aP+ecc9KapjHWDz30UDX+9NNPpzXnnntuNf7II4+kNU2jM7N9PfPMM2nN6aefnuay8dcbN25Ma26++eY0l9Vdcsklac23vvWtanzevHlpjRGiAHBsuSICAAAAaI1GBAAAANAajQgAAACgNRoRAAAAQGs0IgAAAIDWlE6nkydLSZP3339/NX7XXXel29uwYUOay6ZtfOMb30hr9uzZU43Pnz8/rcmmIETkdwufMWNGWpNN+4iI2LRpUzXedNf0P/3TP01zHL03vOENaW7YsLwfl01ZaaqZOHFiNd40nSOb2BKRf50vX748rfmrv/qrNMex0el08lEOA6RpTT6ZNH3t33rrrWluzpw51fiBAwfSmqbpE9OmTavGm6YfNa0D2fSJrVu3pjXZBKumaU9TpkxJczt27KjGmyZMnHrqqWkum2I1atSotKbp7zeb+LFq1aq0Jvs+fccdd6Q1HP+O9ZpsPQY4Mtl67IoIAAAAoDUaEQAAAEBrNCIAAACA1mhEAAAAAK3RiAAAAABaoxEBAAAAtOaox3dmFi1alObe+c53prlspNnYsWP7XdM0JrRJtr3du3enNTNnzkxzK1eu7PcxfPKTn+x3DYf3jne8I81lIzoj8tGtTeP5sq+XU045Ja3Zu3dvmsvG8I0cOTKt2blzZ5r71Kc+leY4esZ3Dg1PPvlkmsvGNR7tZ/Phhx+uxi+66KK0ZsuWLWkuG4P52GOPpTXZ6OumNWDt2rVprpT6l/G+ffvSmjPPPDPNZevr/v3705qmEdwLFy6sxrNRqhH5ev3pT386reH4Z3znyeVnf/Znq/G//du/bflIBtcNN9yQ5u6+++4WjwR+yPhOAAAAYNBpRAAAAACt0YgAAAAAWqMRAQAAALRGIwIAAABojUYEAAAA0JoBH995tL74xS9W402jBpvGLmaaxoFm47+aRjXu2rUrzS1YsKAa37hxY1rzsY99LM1x9N7whjekua1bt6a5iy++uBpvGhE4ffr0fu+n6Wv57LPPrsabxgqOGjUqzWXjRUeMGJHWfOhDH0pzdBnfOfRlo8u+8pWvpDVN45uz3KRJk9Ka7du3p7lzzz23Gt+0aVNaM3ny5Gq8aY3avHlzmrvmmmuq8fvuuy+taRrtmY0kbRqZetZZZ6W59evXV+NN6+H73ve+NMeJy/jO49PrXve6NNe0Fl5xxRXVeLZmRER8+MMfPvIDG0JuueWWNHfgwIE0l33Pyr6PRES8973vPeLjgozxnQAAAMCg04gAAAAAWqMRAQAAALRGIwIAAABojUYEAAAA0JohMzVjIDXdLfxd73pXmsvu4t00GWPp0qVp7sorr0xzGdMJnpsbbrihGs8mWUREfPvb305zV111VTU+ceLEtGbFihXVeNOd5ZvMnDmzGv/Xf/3XtOb8889Pc9nn42d+5mfSmle/+tVpbvbs2WnuZGJqxvFr+fLlae62225Lc9mdxpu+Z+zfvz/NZXc7b5pykU2lGD9+fFrTdBf5bHtNd6tvWgMeffTRanzMmDFpTdPrveeee9Ic9GZqxuC7/vrr01x2btM0Rezqq69Oc48//ng1vnLlyrRm5MiRaW748OH9ikdEnHHGGdV401Sypn9HZNP3ms7/sklrEfn3mKapQ9lEwYiICRMmVOO/+7u/m9ZwcjI1AwAAABh0GhEAAABAazQiAAAAgNZoRAAAAACt0YgAAAAAWqMRAQAAALTmhBzfycnrTW96UzV+8ODBtGbYsLwfN2vWrGp80aJFaU022rNpBNLixYvTXDYqav78+WlNNqIpImLNmjXV+IwZM9KaphFXf/AHf5DmTibGd558su+fN910U1qTff4i8rVj9+7daU02OnP16tVpTdMI0Z07d1bjU6dOTWu2bNmS5rJRcrfffntaAwPB+M52vO51r0tzTaMus/Vz9OjRac2UKVPS3NNPP12NZ2NCI5rX1mzk+qRJk9Kabdu29Sse0XxumJ2fNq252RoeEXHFFVdU4wsXLkxrzjnnnDSXva6mf1veeeedaY4Tl/GdAAAAwKDTiAAAAABaoxEBAAAAtEYjAgAAAGiNRgQAAADQmhGDfQDQX7fcckuaW7VqVTXedGfkprvBb9q0qRofN25cWjN9+vRq/Mknn0xrmu4SvX379mp8/fr1ac348ePT3JgxY6rxlStXpjVNd53+2te+Vo1fffXVaQ2cCEo55oNSAIaExx57rBq/7bbb0ppsElBEft7z1FNPpTVNEyZOOeWUarxpatqoUaPSXHbes3Xr1rTmhS98YTW+YsWKtKZpwlF2vjZ27Ni05vzzz09za9eurcYXLFiQ1jRNwMjeizlz5qQ10JsrIgAAAIDWaEQAAAAArdGIAAAAAFqjEQEAAAC0RiMCAAAAaI1GBAAAANAa4zsZkt7ylrekuXXr1qW5ESPqX9KnnnpqWjN79uw09+1vf7sa37NnT1qTjYM6cOBAWtM04mrSpEnV+M6dO9OajRs39ntf+/btS2s2bNiQ5ppGhQIAx7+77767Gm86H2oacZyNR581a1Zas2jRojQ3d+7carzp/KXpfPKyyy6rxjdv3pzWfOYzn6nGn//856c155xzTprLxrQ3jR19+OGH01xWt3///rRm9+7daS47r216z1/1qldV43//93+f1nDickUEAAAA0BqNCAAAAKA1GhEAAABAazQiAAAAgNZoRAAAAACt0YgAAAAAWmN8J4Pql3/5l6vxCRMmpDVNYysvvvjiavzrX/96WvPMM8+kudWrV1fj1113XVqzdu3aavyMM85Ia4YPH57mHnjggWp8/vz5R7W9TNPIrLFjx6a5bLwoAHD8+Md//Mc0t3jx4mr8ggsuSGtWrlyZ5rLxncOG5T8jnTNnTpobOXJkNd50PnTttdemuWxMZ9NI0gULFlTjTeM2ly1bluaykfTZexcRMWXKlDSXmTZtWpp76qmn0lx2rt50nt7098vJx1cDAAAA0BqNCAAAAKA1GhEAAABAazQiAAAAgNZoRAAAAACtMTXjJHbrrbdW49mkiIiIffv2VeO7du1Kay655JI0t27dump8//79ac3kyZPT3MKFC6vxGTNm9PsYIvK7QX/xi19Ma6ZPn16Nz5w5M63ZsmVLmrvwwgur8aa/p2x6SETExo0b+xWPiJg6dWqacwdkADj+nXfeeWnua1/7WjWeTXaIiDhw4ECay87lRo8endasWLEizWXTva666qq05umnn05z27Ztq8az6RwR+ettOodqOpfLppIdzWSMiPy9feSRR9KapvPnbCLJmDFj+n0MnJz8CwIAAABojUYEAAAA0BqNCAAAAKA1GhEAAABAazQiAAAAgNZoRAAAAACtMb7zJPa6172uGv/gBz+Y1mTjkZpGODblJkyYUI2vWbMmrWkag7lkyZJq/IorrkhrzjjjjDSXjSDasGFDWpONK216TZ1OJ81l46rOPffctKZpFOfEiROr8SeeeCKtyUaSRuTjmwCA40fTeUU2vvMLX/hCWjNu3Lg0t3Xr1mr8oYceSmsuuuiiNHfWWWf1e3vZ+VBEPla96Rx006ZN1XjTiM4m2XuUjRY9XC4bI5qNiY9oHnGfnWs2jZB/5StfWY3fddddaQ0nLldEAAAAAK3RiAAAAABaoxEBAAAAtEYjAgAAAGiNRgQAAADQGo0IAAAAoDXGd57EsnE9e/fuTWtuvvnmarxpXNCiRYvS3IgR9S/B8ePHpzWPPPJImstGMS1btiytmTFjRprLRi7NmTMnrVm/fn013jTmMhv5FBExd+7cavyUU05Ja/bs2ZPm1q5dW42PHDkyrXnjG9+Y5preCwDg+Jedr23fvj2taRp1edppp1Xj8+bNS2sef/zxNLdy5cpq/ODBg2nNzp0709zs2bOr8WykekTEmWee2e9jaDrfzcafTps2La1p2te+ffuq8V27dqU1TblsX9l5cETEpZdemuY4+bgiAgAAAGiNRgQAAADQGo0IAAAAoDUaEQAAAEBrNCIAAACA1pROp5MnS8mTnJS2bt1ajf/hH/5hWtM0wWHhwoXV+Pz589OaYcPy/ll2F+amO/guXbo0zWV3Jj7jjDPSmmwCxtixY9OaprsmZ1MusmkaERGjR49Oc/fee281/vu///tpzQte8II0R1en0ynHeh/WZIAjc6zXZOtx18MPP5zm/uzP/izNLV++vBpvOn/JzvEi8qkZTz75ZFrzohe9KM1lE+SaJoGsWrWqGm+aZNE0sWzChAn92k9ExHnnnZfmsgknTdNDxowZk+ayiXQf/ehH05psuh0ntmw9dkUEAAAA0BqNCAAAAKA1GhEAAABAazQiAAAAgNZoRAAAAACt0YgAAAAAWmN8JwPi+9//fpr7kz/5kzTXNKYpk40fiogYPnx4Nd40HmnLli1p7sCBA9X4jh070pqzzz67Gl+9enVa0zReNBtX2jSi6aabbkpz+/fvr8bPP//8tIbDM74TYOgwvnPwNY3OfPe7312NT548Oa1Zs2ZNmsvO1573vOf1uyYiH5G5bt26tObcc8+txnfv3p3WPPPMM2nu1FNPrcZnz56d1jz66KNp7vTTT6/Gt23bltY0nT//+q//ejV+ySWXpDWcnIzvBAAAAAadRgQAAADQGo0IAAAAoDUaEQAAAEBrNCIAAACA1mhEAAAAAK0xvpNj7p/+6Z/SXDZK6PnPf35a8+Y3vznNTZkypRpvGp2UjWiKyI+vaXubN2+uxrMxTBERr3jFK9LcS17ykmp88eLFac0LX/jCNMexYXwnwNBhfOfQtnTp0mr8gx/8YFrTNNpzyZIl1fi+ffvSmmnTpqW5vXv3VuNN53/ZePmm878xY8akuZ07d1bjTWNHZ86cmeay0fNNY+zf8573pLm5c+emOejN+E4AAABg0GlEAAAAAK3RiAAAAABaoxEBAAAAtEYjAgAAAGiNqRkcd775zW+muexuwTNmzEhrNmzYkObGjx9fjT/88MNpzcGDB6vxYcPyvt/VV1+d5jg+mJoBMHSYmnF8uv/++9Pc8OHD09wdd9xRje/fvz+tmTNnTprLJkk0TawYNWpUNZ6dS0ZE7Nq1K81lx7569eq0Zv78+WkumzpXSv5RaXqP4EiZmgEAAAAMOo0IAAAAoDUaEQAAAEBrNCIAAACA1mhEAAAAAK3RiAAAAABaY3wnwAAwvhNg6DC+8+SSjdt85JFH0ppx48alualTp1bjGzdu7N+BRcSmTZvS3Ny5c9NcNr7zrLPOSmtWrVqV5mbNmpXm4FgyvhMAAAAYdBoRAAAAQGs0IgAAAIDWaEQAAAAArdGIAAAAAFqjEQEAAAC0xvhOgAFgfCfA0GF8J8DQYHwnAAAAMOg0IgAAAIDWaEQAAAAArdGIAAAAAFqjEQEAAAC0RiMCAAAAaI1GBAAAANAajQgAAACgNRoRAAAAQGs0IgAAAIDWaEQAAAAArdGIAAAAAFqjEQEAAAC0RiMCAAAAaI1GBAAAANAajQgAAACgNRoRAAAAQGs0IgAAAIDWaEQAAAAArdGIAAAAAFqjEQEAAAC0RiMCAAAAaI1GBAAAANAajQgAAACgNRoRAAAAQGs0IgAAAIDWaEQAAAAArdGIAAAAAFqjEQEAAAC0RiMCAAAAaI1GBAAAANAajQgAAACgNRoRAAAAQGs0IgAAAIDWaEQAAAAArdGIAAAAAFqjEQEAAAC0RiMCAAAAaI1GBAAAANAajQgAAACgNRoRAAAAQGs0IgAAAIDWaEQAAAAArdGIAAAAAFqjEQEAAAC0pnQ6ncE+BgAAAOAk4YoIAAAAoDUaEQAAAEBrNCIAAACA1mhEAAAAAK3RiAAAAABaoxEBAAAAtOb/BwiUS5ge+SvEAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1080x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "font = {'family': 'serif', 'color':  'black', 'weight': 'normal', 'size': 15}\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "axs[0].imshow(img_mask_to_uint8(nn_video[n_frames//3][0],nn_video[n_frames//3][1]), cmap='gray')\n",
    "axs[0].set_title(r'Segmented Region $(t = 60s)$',fontdict=font)\n",
    "axs[1].imshow(nn_video[2*n_frames//3][0]*nn_video[2*n_frames//3][1], cmap='gray')\n",
    "axs[1].set_title(r'Segmented Region $(t = 120s)$',fontdict=font)\n",
    "axs[2].imshow(nn_video[-1][0]*nn_video[-1][1], cmap='gray')\n",
    "axs[2].set_title(r'Segmented Region $(t = 180s)$',fontdict=font)\n",
    "for ax in axs.flat:\n",
    "    ax.set_axis_off()\n",
    "\n",
    "fig.tight_layout()\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['pdf.fonttype'] = 42 \n",
    "mpl.rcParams['ps.fonttype'] = 42\n",
    "mpl.rcParams['text.usetex'] = False\n",
    "plt.savefig('unet_sup.pdf', dpi=300, transparent=False, bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
